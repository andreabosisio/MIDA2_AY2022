\newlecture{Sergio Savaresi}{05/05/2020}

\subsection{Block-scheme representation of K.F.}
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[node distance=2.5cm,auto,>=latex']
        \node [int] (z1) at (1,4) {$z^{-1}$};
        \node [int] (F1) at (1,3) {$F$};
        \node [int] (K) at (1,2) {$K(t)$};
        \node [int] (z2) at (1,1) {$z^{-1}$};
        \node [int] (F2) at (1,0) {$F$};

        \node [int] (H1) at (4,4) {$H$};
        \node [int] (H2) at (4,1) {$H$};

        \node [sum] (sum1) at (6,4) {};
        \node [sum] (sum2) at (7,2) {};
        \node [sum] (sum3) at (-1.5,4) {};
        \node [sum] (sum4) at (-1.5,1) {};

        \node (v1) at (-1.5,5) {$v_1(t)$};
        \node (v2) at (6,5) {$v_2(t)$};
        \node[right] (y) at (8,4) {$y(t)$};
        \node[right] (yhat) at (8,1) {$\hat{y}(t|t-1)$};
        \node[right] (xhat) at (8,0) {$\hat{x}(t|t-1)$};

        \node at (-1,2.3) {\emph{feedback}};

        \draw[->] (v1) -- (sum3);
        \draw[->] (sum3) -- (z1) node[pos=0.5] {$x(t+1)$};
        \draw[->] (F1) -| (sum3);
        \draw[->] (z1) -- (H1) node[pos=0.5] {$x(t)$};
        \draw[->] (H1) -- (sum1);
        \draw[->] (v2) -- (sum1);
        \draw[->] (2.5,4) |- (F1);
        \draw[->,red,line width=0.5mm] (K) -| (sum4);
        \draw[->] (sum4) -- (z2) node[pos=0.5] {$\hat{x}(t+1|t)$};
        \draw[->] (7,4) -- (sum2) node[pos=0.8] {$+$};
        \draw[->] (sum1) -- (y);
        \draw[<-,red,line width=0.5mm] (K) -- (sum2) node[pos=0.5,black] {$e(t)$};
        \draw[->] (z2) -- (H2) node[pos=0.5] {$\hat{x}(t|t-1)$};
        \draw[->] (F2) -| (sum4);
        \draw[->] (2.5,1) |- (F2);
        \draw[->] (H2) |- (yhat);
        \draw[->,red,line width=0.5mm] (7,1) -- (sum2) node[pos=0.8] {$-$};
        \draw[->] (F2) -- (xhat);
    \end{tikzpicture}
\end{figure}

The idea behind Kalman Filter is simple and intuitive:
\begin{itemize}
    \item We make a simulated replica of the system (without noises $v_1$ and $v_2$, not measurable)
    \item We compare the true measured output with the estimated/simulated output $\hat{y}(t|t-1)$
    \item We make corrections on K.F. main equation, proportional (with gain $K(t)$) to the output error in order to keep K.F. as close as possible to the system
    \item We extract the state estimation $\hat{x}(t|t-1)$
\end{itemize}

Kalman Filter is a feedback system.
Feedback here is not used for control, but for estimation.

This general structure was known before Kalman Filter development, it's called \emph{state observer}.
Fundamental contribution of Kalman was to find the optimal gain $K(t)$.
$K(t)$ is not a simple scalar gain but is a (maybe very large) $n\times p$ matrix.

The selection of gain matrix $K(t)$ is very critical:
\begin{itemize}
    \item If $K(t)$ is \emph{too small}: the estimation is not optimal because we are \emph{under exploiting} the information in $y(t)$
    \item If $K(t)$ is \emph{too big}: risk of over-exploiting $y(t)$ and we can get noise amplification, even risk of instability
\end{itemize}

Design of Kalman Filter does not require a \emph{training dataset}, but a complete model of the system:
\begin{itemize}
    \item $F$, $G$, $H$ matrixes: usually obtained with a white-box physical modelling of the system
    \item $V_1$, $V_2$ and $V_{12}$: $V_2$ is easily built from sensor specifications; $V_1$ much more difficult to be designed (it's the most critical design parameter of K.F.)
\end{itemize}

\section{Extensions of Basic Problem of Basic System}

\subsection{Exogenous input}
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[node distance=2.5cm,auto,>=latex']
        \node [int] (z1) at (1,4) {$z^{-1}$};
        \node [int] (F1) at (1,3) {$F$};
        \node [int] (K) at (1,2) {$K(t)$};
        \node [int] (z2) at (1,1) {$z^{-1}$};
        \node [int] (F2) at (1,0) {$F$};

        \node [int] (H1) at (4,4) {$H$};
        \node [int] (H2) at (4,1) {$H$};

        \node [int] (G1) at (-3,4) {$G$};
        \node [int] (G2) at (-3,1) {$G$};

        \node[left] (u) at (-4,4) {$u(t)$};

        \node [sum] (sum1) at (6,4) {};
        \node [sum] (sum2) at (7,2) {};
        \node [sum] (sum3) at (-1.5,4) {};
        \node [sum] (sum4) at (-1.5,1) {};

        \node (v1) at (-1.5,5) {$v_1(t)$};
        \node (v2) at (6,5) {$v_2(t)$};
        \node[right] (y) at (8,4) {$y(t)$};
        \node[right] (yhat) at (8,1) {$\hat{y}(t|t-1)$};
        \node[right] (xhat) at (8,0) {$\hat{x}(t|t-1)$};

        \node at (-1,2.3) {\emph{feedback}};

        \draw[->,red,line width=0.5mm] (u) -- (G1);
        \draw[->,red,line width=0.5mm] (G1) -- (sum3);
        \draw[->,red,line width=0.5mm] (-3.8,4) |- (G2);
        \draw[->,red,line width=0.5mm] (G2) -- (sum4);
        \draw[->] (v1) -- (sum3);
        \draw[->] (sum3) -- (z1) node[pos=0.5] {$x(t+1)$};
        \draw[->] (F1) -| (sum3);
        \draw[->] (z1) -- (H1) node[pos=0.5] {$x(t)$};
        \draw[->] (H1) -- (sum1);
        \draw[->] (v2) -- (sum1);
        \draw[->] (2.5,4) |- (F1);
        \draw[->] (K) -| (sum4);
        \draw[->] (sum4) -- (z2) node[pos=0.5] {$\hat{x}(t+1|t)$};
        \draw[->] (7,4) -- (sum2) node[pos=0.8] {$+$};
        \draw[->] (sum1) -- (y);
        \draw[<-] (K) -- (sum2) node[pos=0.5,black] {$e(t)$};
        \draw[->] (z2) -- (H2) node[pos=0.5] {$\hat{x}(t|t-1)$};
        \draw[->] (F2) -| (sum4);
        \draw[->] (2.5,1) |- (F2);
        \draw[->] (H2) |- (yhat);
        \draw[->] (7,1) -- (sum2) node[pos=0.8] {$-$};
        \draw[->] (F2) -- (xhat);
    \end{tikzpicture}
\end{figure}

Notice that $K(t)$ remains the same because $P(t)$ is the covariance of the prediction error on $x(t)$ and remains the same because $Gu(t)$ doesn't introduce any additional noise or uncertainties to the system.
$Gu(t)$ is a totally known (deterministic) signal.

\subsection{Multi-step Prediction}

Assume that $\hat{x}(t+1|t)$ is known from the basic solution, we can simply obtain a multi-step prediction as:
\begin{align*}
    \hat{x}(t+2|t) &= F \hat{x}(t+1|t) \\
    \hat{x}(t+3|t) &= F \hat{x}(t+2|t) = F^2\hat{x}(t+1|t) \\
    \vdots \\
    \hat{x}(t+k|t) &= F^{k-1} \hat{x}(t+1|t) \\
    \hat{y}(t+k|t) &= H\hat{x}(t+k|t)
\end{align*}

\subsection{Filter ($\hat{x}(t|t)$)}

\[
    \hat{x}(t+1|t) = F\hat{x}(t|t) \quad \implies \quad \hat{x}(t|t) = F^{-1}\hat{x}(t+1|t)
\]

This formula can be used only if the $F$ is invertible.
If $F$ is not invertible, the filter can be obtained with a specific \emph{filter} formulation of K.F.

Kalman Filter in the filter form is:
\begin{align*}
    \hat{x}(t|t) &= F\hat{x}(t-1|t-1) + Gu(t-1) + K_0(t)e(t) \\
    \hat{y}(t|t-1) &= H\hat{x}(t|t-1) \\
    e(t) &= y(t) - \hat{y}(t|t-1) \\
    K_0(t) &= \left(P(t)H^T\right) \left(HP(t)H^T+V_2\right)^{-1} \\
    \text{DRE}& \text{ unchanged}
\end{align*}

\begin{remark}
    These equations are valid under the restrictive assumption $V_{12} = 0$.
\end{remark}

\begin{remark}
    Gain of K.F. in prediction form:
    \[
        K(t) = \left( FP(t)H^T \right) \left( HP(t)H^T+V_2 \right)^{-1}
    \]

    Gain of K.F. in filter form:
    \[
        K_0(t) = \left( \underline{\phantom{F}} P(t)H^T \right) \left( HP(t)H^T+V_2 \right)^{-1}
    \]
\end{remark}


\subsection{Time-varying systems}

\[
    S: \begin{cases}
        x(t+1) = F(t)x(t) + G(t)u(t) + v_1(t) \\
        y(t) = H(t)x(t) + v_2(t)
    \end{cases}
\]

Kalman Filter equations are exactly the same.

\subsection{Non Linear Systems}

This extensions is much more complicated: Extended Kalman Filter (EKF).

\section{Asymptotic Solution of K.F.}

Observe that K.F. is not itself an LTI system but is a LTV system, because the gain $K(t)$ is time-varying.

The fact that K.F. is a LTV system is the source of 2 problems:
\begin{itemize}
    \item Checking the stability of K.F. algorithm is very difficult. The stability check of an LTV system is not simple as the stability check for LTI.
    \item Computational problem: $K(t)$ must be computed at each sampling time (e.g. every 5ms), including the inversion of $HP(t)H^T+V_2$ ($p\times p$ matrix).
\end{itemize}

\begin{remark}
    For LTI: $x(t+1) = Fx(t) + Gu(t)$ the stability check considers the eigenvalues of $F$.

    For LTV: $x(t+1) = F(t)x(t) + G(t)u(t)$, even if all the eigenvalues of $F(t)$ are strictly inside the unit circle at any time, the system is not guaranteed to be asymptotically stable.
    In practice it is, if the time-variations are \emph{slow}, like in aging.
\end{remark}

Because of those problems in real/practical applications the asymptotic version of K.F. is preferred.

\paragraph{Basic idea}
If $P(t)$ converges to a constant value $\overline{P}$ (steady-state value of $P(t)$), then also $K(t)$ will converge to $\overline{K}$ (steady-state value of $K(t)$).
Using $\overline{K}$ the K.F. becomes an LTI system.

Let's analyze the asymptotic stability of K.F. when $\overline{K}$ is used (assuming it exists).

\begin{align*}
    \hat{x}(t+1|t) &= F\hat{x}(t|t-1) + Gu(t) + \overline{K}e(t) \\
    &= F\hat{x}(t|t-1) + Gu(t) + \overline{K}(y(t) - \hat{y}(t|t-1)) \\
    &= F\hat{x}(t|t-1) + Gu(t) + \overline{K}(y(t) - H\hat{x}(t|t-1)) \\
    &= \underbrace{(F - \overline{K}H)}_{\text{new state matrix}} \hat{x}(t|t-1) + Gu(t) + \overline{K}y(t)
\end{align*}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[node distance=2.5cm,auto,>=latex']
        \node[int] (K) at (1,1) {$\overline{K}$};
        \node[int] (G) at (1,2) {$G$};
        \node[sum] (sum) at (3,1) {};
        \node[int] (z) at (6,1) {$z^{-1}$};
        \node[int] (fb) at (6,0) {$F-\overline{K}H$};

        \node[left] (y) at (0,1) {$y(t)$};
        \node[left] (u) at (0,2) {$u(t)$};

        \draw[->] (y) -- (K);
        \draw[->] (u) -- (G);
        \draw[->] (K) -- (sum);
        \draw[->] (sum) -- (z) node[pos=0.5] {$\hat{x}(t+1|t)$};
        \draw[->] (z) -- (9,1) node[pos=0.5] {$\hat{x}(t|t-1)$};
        \draw[->] (fb) -| (sum);
        \draw[->] (G) -| (sum);
        \draw[->] (7.5,1) |- (fb);
    \end{tikzpicture}
\end{figure}

If $\overline{K}$ exists, the K.F. is asymptotically stable if and only if all the eigenvalues of $F-\overline{K}H$ are strictly inside the unit circle.

\begin{remark}
    The stability of the system $S$ is related to matrix $F$, whereas the stability of K.F. is related to matrix $F-\overline{K}H$.

    K.F. can be asymptotically stable even if the system is unstable.
\end{remark}

\paragraph{Existance of $\overline{K}$}

\[
    \overline{K} = \left(F\overline{P}H^T + V_{12}\right)\left(H\overline{P}H^T+V_2\right)^{-1}
\]

$\overline{K}$ exists if $\overline{P}$ exists.
We need to check the converge properties of D.R.E.

To find the equilibrium of a dynamical autonomous system:

\begin{center}
    \begin{tabular}{c|c}
        \textbf{Continuous time} & \textbf{Discrete time} \\
        \hline
        $\dot{x} = f(x)$ & $x(t+1) = f(x(t))$ \\
        equilibrium when $\dot{x} = 0$ & equilibrium when $x(t+1) = x(t)$ \\
        $f(\overline{x}) = 0$ & $f(\overline{x}) = \overline{x}$ \\
    \end{tabular}
\end{center}

D.R.E. is an autonomous discrete time system:
\[
    \overline{P} = f(\overline{P}) = \left( F\overline{P}F^T + V_1 \right)-\left(F\overline{P}H^T + V_{12}\right)\left(H\overline{P}H^T + V_2\right)^{-1}\left(F\overline{P}H^T+V_{12}\right)^T
\]

It's a non linear algebraic equation, known as Algebraic Riccati Equation (A.R.E.).

If a steady state $\overline{P}$ solution of D.R.E. does exists, it must be a solution of A.R.E.
There remains 3 questions:
\begin{description}
    \item[Existence] Does A.R.E. have a semi-definite positive solution?
    \item[Convergence] If exists, does the D.R.E. converges to $\overline{P}$?
    \item[Stability] Is the corresponding $\overline{K}$ such that the K.F. is asymptotically stable?
\end{description}
